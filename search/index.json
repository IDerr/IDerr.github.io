[{"content":"Introduction In the last article, we have imported OpenFoodFacts data from a CSV format to PostgreSQL.\nNow, our data is ready to be analysed by anyone. SQL can be great for analysis but if we want to build an application, we\u0026rsquo;ll need another transport layer like REST or GraphQL. So in this article, I\u0026rsquo;ll show you how create a quick GraphQL API using Hasura\nYou can find all my work on my Github : https://github.com/IDerr/Openfoodfacts\nWhat is Hasura Hasura is a GraphQL engine that can be connected to your database and result in a unified data access layer, here GraphQL.\nIf you\u0026rsquo;re interested by the project, you can find a lot more informations on their website !\nInstallation Installation of hasura is pretty straight forward, I\u0026rsquo;ll use Docker-compose to simplify this process.\nHere\u0026rsquo;s the docker-compose I\u0026rsquo;ve used to create my hasura engine\nversion: '3.6'\rservices:\rgraphql-engine:\rimage: hasura/graphql-engine:v2.0.10\rports:\r- 8080:8080\rrestart: always\renvironment:\r## postgres database to store Hasura metadata\rHASURA_GRAPHQL_METADATA_DATABASE_URL: postgresql://username:password@hostname:5432/mymetadatadatabase\r## this env var can be used to add the above postgres database to Hasura as a data source. this can be removed/updated based on your needs\rPG_DATABASE_URL: postgresql://username:password@hostname:5432/openfoodfacts\r## enable the console served by server\rHASURA_GRAPHQL_ENABLE_CONSOLE: \u0026quot;true\u0026quot; # set to \u0026quot;false\u0026quot; to disable console\r## enable debugging mode. It is recommended to disable this in production\rHASURA_GRAPHQL_DEV_MODE: \u0026quot;true\u0026quot;\rHASURA_GRAPHQL_ENABLED_LOG_TYPES: startup, http-log, webhook-log, websocket-log, query-log\r## uncomment next line to set an admin secret\r# HASURA_GRAPHQL_ADMIN_SECRET: myadminsecretkey\rNow you run the tool easily with\ndocker-compose up -d  1.jpg \nTADAA, you know have a hasura engine ready, just type  http://youhostname:8080/console You\u0026rsquo;ll be welcomed with a super UI.\nYou can now go to the \u0026ldquo;Data\u0026rdquo; section where you can setup the relationship between your database and Hasura.\n 2.jpg \nJust track everything to link all tables !\nThen it\u0026rsquo;ll automatically detect all the links between tables, track them also.\n 3.jpg \nAfter that, you can come back in the \u0026ldquo;API\u0026rdquo; section and your API is ready !\nWe can now easily create our GraphQL requests, for example all products that doesn\u0026rsquo;t have a creator\nqueryGetProductsWithoutCreator{Product(where:{creator:{_is_null:true}}){codecreatorproduct_name}} 4.jpg \nOh, we have found 4 products without any creator, weird\u0026hellip;\nWe can now report that to the OpenFood facts team :)\nAnalysis can be done very quicky with tools like this, and if we want to build an Android app, our API will be ready to go !\nNext steps Next steps, develop more GraphQL queries to find inconsistent data \u0026amp; improve the data model. I\u0026rsquo;ll focus on that now !\nAlso, that we have our API, we can try to make a simple app to try the integration with Hasura.\nConclusion I\u0026rsquo;ll continue working on my side, if anyone would like to help me on this project, feel free to create issues and PR on the github repository. I am also available on Openfoodfacts Slack (IDerr), if there\u0026rsquo;s any questions!\nSee you next week for the next article (on OpenFoodFacts)!\n","date":"2021-11-19T00:00:00Z","image":"https://iderr.github.io/p/week-2-improving-openfoodfacts/background_hu7f4aefc3a426d3b4990b4956a4ec486a_256879_120x120_fill_box_smart1_3.png","permalink":"https://iderr.github.io/p/week-2-improving-openfoodfacts/","title":"Week 2 - Improving OpenFoodFacts"},{"content":"Introduction Today we will discuss how to import OpenFoodFacts data from their CSV to a PostgreSQL Database.\nI wanted to work on OpenFoodFacts data, but never found MongoDB really great to work with, so I decided to migrate the CSV Data to Postgres, and clean the database (and give back a bit to this awesome community)\nYou can find all my work on my Github : https://github.com/IDerr/Openfoodfacts\nHow to download OpenFoodFacts data OpenFoodFacts provides all their data for free on their website, with three different formats: Json (based on their mongodb database), CSV and RDF You can download al the data on their website: https://openfoodfacts.org/data\nFor the sake of simplicity, I\u0026rsquo;ll use the CSV format for my project.\nHow to import data from the CSV to PostgreSQL As I said, I\u0026rsquo;ll store my data on PostgreSQL, I think this is a great way to store linked data like this (A graph database would be a good fit also), it\u0026rsquo;ll enforce that all fields are filled and the schema respected.\nI took the CSV file, checked all the columns available, and went with a simple schema (still can be improved :D).\nI have determined 12 Models (Additives, Allergens, Brand, Category, City, Country, Emb, Label, Package, Product, Store, Trace) and a bunch of Pivot tables for many to many relations.\nTo implement models files, I used SQLAlchemy to create my database schema programmatically, so I can reuse those models files if I want to interact with the database.\nA small python script to parse the CSV, remove incorrect data (same barcode on multiple products ?), and create the product with full links, and tada, we have our database with a lot of products!\n count \nNext steps Now that our database is ready, there is still work that can be done. The first step I see is cleaning possible errors or inconsistent data. We have multiple ways to analyse the database to find these errors:\n Use the CSV with some Python to detect anomalies (Pandas + some code) Use SQL to find anomalies (or again use Pandas with SQL as a backend)  After that part, we can make an API based on the models we created before, to integrate the database with our applications!\nFinally, finding ways to improve our database, translations, ingredients, score and so on!\nConclusion I\u0026rsquo;ll continue working this project on my side, if anyone would like to help me on this project, feel free to create issues and PR on the github repository. I am also available on Openfoodfacts Slack (IDerr), if there\u0026rsquo;s any questions!\nIf anyone from openfoodfacts is interested on merging the work I am doing on the public database, don\u0026rsquo;t hesitate! See you next week for the next article (on OpenFoodFacts)!\n","date":"2021-11-14T00:00:00Z","image":"https://iderr.github.io/p/week-1-new-project-on-openfoodfacts/background_hu49c03114a9ce8ad2bc0bd62c0ddb3f2a_750790_120x120_fill_box_smart1_3.png","permalink":"https://iderr.github.io/p/week-1-new-project-on-openfoodfacts/","title":"Week 1 - New project on OpenFoodFacts"},{"content":"Introduction Today, we will discuss how to use Tutor for deploying OpenEdx. OpenEdx is a platform used to deploy your courses online, it\u0026rsquo;s an Udemy like but self hosted.\nTutor is an amazing tool to get it deployed with Docker (or Kubernetes).\nInstallation Tutor installation Installation is really straightforward, a simple binary to download and you\u0026rsquo;re done !\nsudo curl -L \u0026#34;https://github.com/overhangio/tutor/releases/download/v12.1.6/tutor-$(uname -s)_$(uname -m)\u0026#34; -o /usr/local/bin/tutor sudo chmod 0755 /usr/local/bin/tutor Shamefully copied/pasted from the documentation\nReally simple, no ?\nRun your environnement Now that we have Tutor installed in our environnement, we can launch our platform with the following command\ntutor local quickstart\rYou\u0026rsquo;ll be asked some questions to change some variables :\n Is it a production platform ? Our instance name Our contact email  For this tutorial, I\u0026rsquo;ll run a non production openedx.\niderr@iderr-VirtualBox:~$ tutor local quickstart ================================================== Interactive platform configuration ================================================== Are you configuring a production platform? Type \u0026#39;n\u0026#39; if you are just testing Tutor on your local computer [Y/n] n As you are not running this platform in production, we automatically set the following configuration values: LMS_HOST = local.overhang.io CMS_HOST = studio.local.overhang.io ENABLE_HTTPS = False Your platform name/title [My Open edX] platform1 Your public contact email address [contact@local.overhang.io] The default language code for the platform [en] Configuration saved to /home/iderr/.local/share/tutor/config.yml Environment generated in /home/iderr/.local/share/tutor/env We let tutor do its job, and your environnement will be ready after seeing a text message like this\nAll services initialised.\rThe Open edX platform is now running in detached mode\rYour Open edX platform is ready and can be accessed at the following urls:\rhttp://local.overhang.io\rhttp://studio.local.overhang.io\rFor our test, I\u0026rsquo;ll stick with defaults urls, of course, you can use yours. I\u0026rsquo;ll modify my /etc/hosts file to redirect urls in my localhost environnement\n127.0.0.1\tlocalhost local.overhang.io studio.local.overhang.io\rTADA  Success \nConclusion Congratulations, now, we have a running OpenEdx installation ! See you next time for the configuration of OpenEdx and its customisation !\n","date":"2021-11-07T00:00:00Z","image":"https://iderr.github.io/p/introduction-to-tutor/background_hu4902f2b049033e1a8195559260a8ee86_735658_120x120_fill_box_smart1_3.png","permalink":"https://iderr.github.io/p/introduction-to-tutor/","title":"Introduction to Tutor"},{"content":"Introduction First article of this new blog!\nToday we will discuss how to configure automatic Letâ€™s-Encrypt certificate renewal with a domain hosted in OVH.\nI have not found a clear tutorial on how to setup a cluster wide OVH cert-manager provider so there it is.\nInstallation Cert-manager installation Quick reminder, installing cert-manager is pretty straightforward with Helm. Don\u0026rsquo;t forget to replace the version with the latest one : https://github.com/jetstack/cert-manager/releases\nkubectl create namespace cert-manager helm repo add jetstack https://charts.jetstack.io helm repo update helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --version v1.5.3 --set installCRDs=true After that, you should have a running cert-manager.\nOVH Webhook installation git clone https://github.com/baarde/cert-manager-webhook-ovh.git cd cert-manager-webhook-ovh helm install cert-manager-webhook-ovh ./deploy/cert-manager-webhook-ovh --set groupName=\u0026#39;\u0026lt;GROUP_NAME\u0026gt;\u0026#39; After that, we need to create our api keys in the OVH API to connect our webhook controller to OVH\n Go to https://api.ovh.com/createToken/index.cgi Add the followings rights, if you want to give acces to all of your domains  GET /domain/zone/* PUT /domain/zone/* POST /domain/zone/* DELETE /domain/zone/*   If you prefer to give access only to one domain replace the \u0026ldquo;*\u0026rdquo; by your domain name  We will store the freshly generated application secret in Kubernetes.\nThe secret needs to be in the same namespace as the cert-manager controller pod if you want to create a ClusterIssuer, in our case, \u0026lsquo;cert-manager\u0026rsquo;\nkubectl create secret generic ovh-credentials --namespace cert-manager --from-literal=applicationSecret=\u0026#39;\u0026lt;OVHSECRET\u0026gt;\u0026#39; Grant permission to get the secret to the cert-manager-webhook-ovh service account\napiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:name:cert-manager-webhook-ovh:secret-readerrules:- apiGroups:[\u0026#34;\u0026#34;]resources:[\u0026#34;secrets\u0026#34;]resourceNames:[\u0026#34;ovh-credentials\u0026#34;]verbs:[\u0026#34;get\u0026#34;,\u0026#34;watch\u0026#34;]---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:name:cert-manager-webhook-ovh:secret-readerroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:cert-manager-webhook-ovh:secret-readersubjects:- apiGroup:\u0026#34;\u0026#34;namespace:defaultkind:ServiceAccountname:cert-manager-webhook-ovhAnd we can finally create our cluster issuer, don\u0026rsquo;t forget to replace the values between \u0026lt;\u0026gt; with your keys/config\napiVersion:cert-manager.io/v1kind:ClusterIssuermetadata:name:letsencryptnamespace:cert-managerspec:acme:server:https://acme-v02.api.letsencrypt.org/directoryemail:\u0026#39;\u0026lt;EMAIL\u0026gt;\u0026#39;privateKeySecretRef:name:letsencrypt-account-keysolvers:- dns01:webhook:groupName:\u0026#39;\u0026lt;GROUP_NAME\u0026gt;\u0026#39;solverName:ovhconfig:endpoint:ovh-euapplicationKey:\u0026#39;\u0026lt;APP_KEY\u0026gt;\u0026#39;applicationSecretRef:key:applicationSecretname:ovh-credentialsconsumerKey:\u0026#39;\u0026lt;CONSUMER_KEY\u0026gt;\u0026#39;And voila, you have a fully working ClusterIssuer with OVH, you can test all your work with a new Certificate.\napiVersion:cert-manager.io/v1kind:Certificatemetadata:name:example-certificatespec:dnsNames:- test.mydomain.comissuerRef:name:letsencryptkind:ClusterIssuersecretName:test-mydomain-com-tlsNAME READY SECRET AGE example-certificate True test-mydomain-com-tls 3s Conclusion Congratulations, and see you next time for another article!\n","date":"2021-08-27T00:00:00Z","image":"https://cdna.artstation.com/p/assets/images/images/009/211/358/large/bala-vidhya-sagar-1.jpg?1517728575","permalink":"https://iderr.github.io/p/ovh-provider-for-cert-manager-dns-01/","title":"OVH provider for cert-manager DNS-01"}]